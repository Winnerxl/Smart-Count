
# Smart Count: Efficient and Affordable Object Counting

Smart Count is a low-cost, real-time object counting system built on an embedded platform using **sensor fusion**. It combines camera-based object detection with depth sensing from a Time-of-Flight (ToF) sensor to improve counting accuracy, especially in occlusion-heavy or stacked scenarios. Designed with affordability and portability in mind, the system runs on a **Raspberry Pi Zero 2W** and an **ESP32** microcontroller.

## ğŸ” Project Highlights

- **Sensor Fusion** of camera and VL53L5CX ToF sensor
- Real-time object detection with **MobileNetV2-SSD** (TensorFlow Lite)
- Accurate depth sensing using 8Ã—8 low-resolution grid
- Adaptive object height calibration
- Calibration via **perspective transform**
- Simple and responsive **web interface** (Flask + Socket.IO)
- MQTT-based lightweight communication between components

## ğŸ“¦ Hardware Requirements

| Component | Role |
|----------|------|
| Raspberry Pi Zero 2W | Main processing unit: runs detection, fusion, web UI |
| ESP32 | Collects and transmits ToF depth data via MQTT |
| VL53L5CX ToF Sensor | 8Ã—8 multizone depth sensing |
| USB Webcam | Captures side-view image frames |
| Wi-Fi Access Point | For MQTT communication between devices |

## ğŸ§  Software Stack

- **Language:** Python (Raspberry Pi) & C++ (ESP32)
- **Libraries (Pi):** OpenCV, Flask, Flask-SocketIO, NumPy, SciPy, Paho-MQTT, TensorFlow Lite
- **Libraries (ESP32):** Arduino IDE, SparkFun VL53L5CX Library, PubSubClient, WiFi

## ğŸ–¥ï¸ System Architecture

```
+------------------------+                  +----------------------------+
|   Raspberry Pi Zero    |                  |         ESP32             |
|                        |                  |                            |
|  - Object Detection    | <----- MQTT ---- |  - VL53L5CX ToF Sensor     |
|  - Sensor Fusion       |                  |  - JSON Data Publisher     |
|  - Web Interface       |                  +----------------------------+
|  - Centroid Tracking   |
+------------------------+
```

## âš™ï¸ Installation & Setup

### ğŸ§° 1. Raspberry Pi Setup

```bash
sudo apt update && sudo apt upgrade
sudo apt install python3-opencv python3-pip
pip3 install flask flask-socketio paho-mqtt numpy scipy
```

- Add TensorFlow Lite runtime:
```bash
pip3 install tflite-runtime
```

- Place the TFLite model and COCO label file in `model/` folder:
```
model/
  â”œâ”€â”€ mobilenet_ssd_v2_coco_quant_postprocess.tflite
  â””â”€â”€ coco_labels.txt
```

### ğŸ“¡ 2. ESP32 Firmware

- Use **Arduino IDE**
- Required libraries:
  - `Wire.h`, `WiFi.h`, `PubSubClient`, `SparkFun_VL53L5CX_Library`
- Configure your Wi-Fi and MQTT broker IP in the code
- Upload the firmware to ESP32

### ğŸ¯ 3. Calibration

Run `calibrate.py` on Raspberry Pi:

```bash
python3 calibrate.py
```

This will:
- Guide you to click 4 sensor corner markers on live camera feed
- Save `calibration_matrix.npy` for perspective transform

### â–¶ï¸ 4. Start Counting!

Run main script:

```bash
python3 counting.py
```

Access live web interface:

```
http://<your-pi-ip>:5000
```

## ğŸŒ Web Interface

- Live camera view with bounding boxes
- Real-time count from camera, sensor, and fused result
- 8Ã—8 heatmap of depth sensor
- FPS and BASE_DEPTH indicators

## ğŸ§ª Experimental Results

| Scenario                 | Camera-Only Accuracy | Fused System Accuracy |
|--------------------------|----------------------|------------------------|
| Well-Separated Objects   | 92.8%                | 100%                  |
| Partial Occlusion        | ~70â€“80%              | 100%                  |
| Stacked Objects          | ~80%                 | 90â€“100% (with height estimation) |

## ğŸ“ Project Structure

```
Smart-Count/
â”‚
â”œâ”€â”€ calibrate.py               # Manual sensor-camera calibration
â”œâ”€â”€ counting.py                # Main fusion + UI + detection logic
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ mobilenet_ssd_v2...    # TFLite model
â”‚   â””â”€â”€ coco_labels.txt
â”œâ”€â”€ calibration_matrix.npy     # Generated by calibrate.py
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

## ğŸ§  Key Algorithms

- **Centroid Tracking** for temporal stability
- **Perspective Transform** for ToF-to-Camera spatial alignment
- **Dynamic Object Height Threshold** from depth feedback
- **Sensor-only Object Counting** using average cluster height

## ğŸ‘¨â€ğŸ’» Authors

- Mert Mermer [@Winnerxl](https://github.com/Winnerxl)
- Kerem Ã‡elik
- Yusuf DoÄŸan Ã‡iÃ§ek

Graduation project @ EskiÅŸehir Technical University, 2025  
Supervisor: Assist. Prof. Dr. Altan Onat

## ğŸ“¬ Contact

For questions or collaborations, reach out via GitHub or via [LinkedIn](https://www.linkedin.com/in/mert-mermer).
